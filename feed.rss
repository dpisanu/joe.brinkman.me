<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
	<channel>
		<title>Joe Brinkman</title>
		<link>https://joe.brinkman.me/</link>
		<description>Joe Brinkman</description>
		<copyright>2017</copyright>
		<pubDate>Mon, 06 Nov 2017 22:00:23 GMT</pubDate>
		<lastBuildDate>Mon, 06 Nov 2017 22:00:23 GMT</lastBuildDate>
		<item>
			<title>Can You Hear Me Now? Part 1</title>
			<link>https://joe.brinkman.me/posts/alexa-skill-part-1</link>
			<description>&lt;p&gt;Every decade or two since the advent of computers, there has been a revolutionary product that fundamentally alters the computing landscape and creates massive new business opportunities. In the 70s this revolution was led by the creation of personal computers and the Apple II, Commodore PET and Tandy TRS-80.  In the 80s we saw whole new businesses created as the result of the revolution brought about by the &lt;abbr title="Graphical User Interface"&gt;GUI&lt;/abbr&gt; as exemplified by the Mac OS and Windows. In the 90s some of the largest companies in the world were started based on the creation of the World Wide Web and Netscape Navigator. In 2007 the modern mobile computing era was fueled by the creation of touch based devices and the Apple iPhone. In late 2014, Amazon launched a device which I believe marked the start of another innovation wave.&lt;/p&gt;</description>
			<enclosure url="https://joe.brinkman.me/assets/image/Header.png" length="0" type="image" />
			<guid>https://joe.brinkman.me/posts/alexa-skill-part-1</guid>
			<pubDate>Mon, 06 Nov 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="overview"&gt;Overview&lt;/h2&gt;
&lt;p&gt;Every decade or two since the advent of computers, there has been a revolutionary product that fundamentally alters the computing landscape and creates massive new business opportunities. In the 70s this revolution was led by the creation of personal computers and the Apple II, Commodore PET and Tandy TRS-80.  In the 80s we saw whole new businesses created as the result of the revolution brought about by the &lt;abbr title="Graphical User Interface"&gt;GUI&lt;/abbr&gt; as exemplified by the Mac OS and Windows. In the 90s some of the largest companies in the world were started based on the creation of the World Wide Web and Netscape Navigator. In 2007 the modern mobile computing era was fueled by the creation of touch based devices and the Apple iPhone. In late 2014, Amazon launched a device which I believe marked the start of another innovation wave.&lt;/p&gt;
&lt;p&gt;In this series I'll provide some background on the current state of the industry and walk through creating the sample voice application that we used to demonstrate the API capabilities of Evoq Liquid Content. While the code will be specific to Amazon Alexa and Evoq, the concepts are exactly the same regardless of whether you are creating applications for Amazon Alexa, Google Assistant or Microsoft Cortana.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Part 1:&lt;/strong&gt; What are Voice Applications&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Part 2:&lt;/strong&gt; Defining and Building the Application&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Part 3:&lt;/strong&gt; Testing and Deployment&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="voice-applications"&gt;Voice Applications&lt;/h2&gt;
&lt;p&gt;The way we interact with computers has changed dramatically in the last 50 years. Each advancement seeks to make the interaction more closely resemble human to human interaction. The latest innovation in machine-human interaction was the creation of a mass market device that was built around a &lt;a href="https://en.wikipedia.org/wiki/Voice_user_interface"&gt;&lt;abbr title="Voice User Interface"&gt;VUI&lt;/abbr&gt;&lt;/a&gt;. Amazon Echo is a revolutionary product that popularized the current trend around &amp;quot;smart speakers&amp;quot;, and also created an entire ecosystem around the development of voice applications.&lt;/p&gt;
&lt;p&gt;&lt;img src="/assets/image/alexa-skill/alexa-skill-architecture.png" class="pull-left img-small img-fluid" alt="Voice Application architecture" /&gt;
Voice applications are multi-layered systems that define the interactions and behaviors of an application designed for use where voice is the primary user interaction paradigm. Voice applications are distinct from the traditional application model that relies on visual elements to convey information to users. This high-level architecture is used in the three major voice application platforms (Amazon Alexa, Google Assistant and Microsoft Cortana).&lt;/p&gt;
&lt;p&gt;One of the unique aspects of voice application architecture is that the &lt;abbr title="Voice User Interface"&gt;VUI&lt;/abbr&gt; is defined and hosted by the platform vendor without any coding required, while the application logic can be hosted anywhere. This architecture is the epitome of a microservices based architecture.&lt;/p&gt;
&lt;h3 id="voice-engine"&gt;Voice Engine&lt;/h3&gt;
&lt;p&gt;The magic of any voice application resides in the voice engine (layer #1) provided by the vendor. The developer is responsible for creating the interaction model that the voice engine will use when processing a user's voice interaction. The voice engine uses &lt;a href="https://en.wikipedia.org/wiki/Natural_language_processing"&gt;Natural Language Processing&lt;/a&gt; (&lt;abbr title="Natural Language Processing"&gt;NLP&lt;/abbr&gt;) and &lt;a href="https://en.wikipedia.org/wiki/Speech_recognition"&gt;Automatic Speech Recognition&lt;/a&gt; (&lt;abbr title="Automatic Speech Recognition"&gt;ASR&lt;/abbr&gt;) to translate a user's voice command into a structured command that can be understood by your application.&lt;/p&gt;
&lt;p&gt;Every interaction model starts by defining intents, slots, and sample utterances. More advanced engines also allow you to define dialog flows in order to describe complex interactions which cannot be expressed in a single utterance. The interaction model describes the full capabilities of your application and should be robust enough to handle the complexity of natural language. Like any user interface, the quality of your interaction model will directly impact the experience your users have with your application.&lt;/p&gt;
&lt;p class="bg-info"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Microsoft and Google use the term Entities instead of the term slots. Other than the terminology difference slots and entities are used the same way in the various platforms. &lt;/p&gt;
&lt;p&gt;An intent defines the action that the user would like your application to perform.  It could be querying for some information, changing the state of a device like a light or door, or playing some media. In general, applications should be focused on handling a small number of intents. As the number of intents grows, the user experience begins degrading. For the Alexa platform, in addition to your own intents, you will also need to handle some built-in system intents like help, cancel and stop.&lt;/p&gt;
&lt;p&gt;Slots define the parameters that are used to provide details related to the intent. For example if you said &amp;quot;Alexa, Play the latest song by Katy Perry&amp;quot;, &lt;strong&gt;playsong&lt;/strong&gt; might be the intent, and &lt;strong&gt;latest&lt;/strong&gt; and &lt;strong&gt;Katy Perry&lt;/strong&gt; would be the slots. The intent and slots provide enough information for your application to determine the appropriate action to take.&lt;/p&gt;
&lt;p&gt;At the heart of every voice engine is an &lt;abbr title="Natural Language Processing"&gt;NLP&lt;/abbr&gt; algorithm that must be trained to recognize how to translate a given phrase to the intents and slots that have been defined. The phrases that you train the voice engine with are called utterances. It is not necessary to provide every possible utterance permutation when training the voice application, but enough variety should be provided so that the &lt;abbr title="Natural Language Processing"&gt;NLP&lt;/abbr&gt; algorithm can identify the common phrasing patterns, and from that it will be able to extrapolate all of the ways that someone might express a given intent. Usually, I will define three to five utterances that I think someone might use. When I get into the testing phase I will come up with several alternatives and use those to verify if the model is able to handle those variations. I'll cover that in more detail in a later part of the series.&lt;/p&gt;
&lt;h3 id="application"&gt;Application&lt;/h3&gt;
&lt;p&gt;The heart of a voice application resides in the application layer (layer #2). The application layer exists as a web service that can be called by the voice engine once it detects an utterance associated with the application. While the specific service calls and data format for each voice platform is different, the basics remain the same.&lt;/p&gt;
&lt;p&gt;The voice engine sends a message to the application layer for different application lifecycle events like launch or session end. In addition the engine will call the application when an utterance is matched to an intent. The application is responsible for either starting a dialog interaction to request additional information from the user or fulfilling the intent request. How the application processes each request is completely within the applications control.&lt;/p&gt;
&lt;p&gt;Since the application layer is just a web-service that can receive requests from the voice engine, it can be created using any programming language, framework or service that is capable of exposing an appropriate endpoint. Due to the nature and small size of most voice applications, they are easily hosted using serverless systems like &lt;a href="https://aws.amazon.com/lambda/"&gt;AWS Lambda&lt;/a&gt; or &lt;a href="https://azure.microsoft.com/en-us/services/functions/"&gt;Azure Functions&lt;/a&gt;. While you do not need to use AWS or Azure for hosting your application, those services do offer additional features specifically tailored to running application code for the associated voice engine.&lt;/p&gt;
&lt;h3 id="backend-services"&gt;Backend Services&lt;/h3&gt;
&lt;p&gt;Most voice applications will have a lightweight application layer and will call various backend services and systems (layer #3) for performing the actual work or accessing application data. Often, the application layer just becomes a translation layer or façade for relaying commands from the voice engine to some pre-existing service API(s). In the example application that goes with this series the service layer will be handled by &lt;a href="http://www.dnnsoftware.com/cms-features/about-liquid-content"&gt;Evoq Liquid Content&lt;/a&gt;. As a result, building this layer will be strictly a matter of gaining access to the API via an appropriately scoped API key.&lt;/p&gt;
&lt;h2 id="think-differently"&gt;Think Differently&lt;/h2&gt;
&lt;p&gt;Writing voice applications requires a fundamentally different approach from writing traditional &lt;abbr title="Graphical User Interface"&gt;GUI&lt;/abbr&gt; applications. Developers have spent the last 30 years building visually rich application interfaces. We've incorporated sound and color and motion into our user experiences which helps evoke just the right emotion as users navigate through our applications and websites. The world of &lt;abbr title="Voice User Interface"&gt;VUI&lt;/abbr&gt; applications is very different. It is like going from gigabit Ethernet to a 14.4k modem. In the dialup world, every byte traveling across the wire takes on that much more importance. The same is true in the &lt;abbr title="Voice User Interface"&gt;VUI&lt;/abbr&gt; world, where you need to prioritize the most important information to convey to the user.&lt;/p&gt;
&lt;p&gt;We've all heard the saying &amp;quot;a picture is worth a thousand words&amp;quot;, unfortunately for developers of voice applications the human brain has a very small amount of short term memory. In the &lt;abbr title="Voice User Interface"&gt;VUI&lt;/abbr&gt; world, applications should be designed to present the user with just a few choices or a few pieces of information at one time. If too much information is presented at once, the user will suffer from information overload and won't be able to recall the first portion of the information provided. It is critical that the &lt;abbr title="Voice User Interface"&gt;VUI&lt;/abbr&gt; design presents information in small, bite sized chunks and that information is prioritized so the most important information is presented first.&lt;/p&gt;
&lt;p&gt;Since we can't present the user with all of the information that may be available, voice applications must build in methods to allow users to get the next &amp;quot;chunk&amp;quot; of data or to get help on what other options might be available. You see this quite often in voicemail systems which offer prompts like &amp;quot;press five for additional options&amp;quot;. Rarely will a voice mail system provide 10 different choices for a user, because long before the user reads the 9th option, they will have forgotten options one, two and three.&lt;/p&gt;
&lt;h2 id="putting-it-all-together"&gt;Putting It All Together&lt;/h2&gt;
&lt;p&gt;What should be apparent at this point is that voice applications are different from traditional applications. They require different design thinking and a different application architecture. Voice applications include a voice engine, provided by your voice platform, and they include a custom application layer. Building a voice app is a two step process involving configuring the voice engine, and developing the application layer as a web service. This is readily apparent when building an Alexa Skill as even the most trivial skill will require accessing two different Amazon developer portals: one for the &lt;a href="https://developer.amazon.com/edw/home.html#/skills"&gt;AWS Skill configuration&lt;/a&gt;, and one for &lt;a href="https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions"&gt;hosting your application code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now that the basics are out of the way, I am ready to dive into the details about how to build and host your own voice application running on Amazon Alexa. Stay tuned for part 2 and 3 of this series.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Serverless Blogging</title>
			<link>https://joe.brinkman.me/posts/serverless-blogs</link>
			<description>&lt;p&gt;Serverless computing is all the rage today. Services like AWS Lambda and Azure Functions allow you to build applications without worrying about where your code runs or when to scale up and down the resources for your application. While there is a server somewhere that is running your code, you don't have to worry about it.  All of the server management details are handled for you and you can focus your effort on just your code.&lt;/p&gt;</description>
			<enclosure url="https://joe.brinkman.me/assets/image/Header.png" length="0" type="image" />
			<guid>https://joe.brinkman.me/posts/serverless-blogs</guid>
			<pubDate>Wed, 18 Oct 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="overview"&gt;Overview&lt;/h2&gt;
&lt;p&gt;Serverless computing is all the rage today. Services like AWS Lambda and Azure Functions allow you to build applications without worrying about where your code runs or when to scale up and down the resources for your application. While there is a server somewhere that is running your code, you don't have to worry about it.  All of the server management details are handled for you and you can focus your effort on just your code.&lt;/p&gt;
&lt;h2 id="evaluating-my-options"&gt;Evaluating My Options&lt;/h2&gt;
&lt;p&gt;As I was evaluating different blogging options I shortlisted the features I wanted:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Blogging - must support blogging (posting, commenting, RSS)&lt;/li&gt;
&lt;li&gt;Full Control - can change any aspect I choose&lt;/li&gt;
&lt;li&gt;Low maintenance - operates with little to no intervention&lt;/li&gt;
&lt;li&gt;Lightweight - doesn't have hundreds of unneeded features&lt;/li&gt;
&lt;li&gt;Flexible - the system could be extended if needed. Bonus points if I had the knowledge to create extensions.&lt;/li&gt;
&lt;li&gt;Scalable - should be easy to host and handle almost unlimited load&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In evaluating systems I looked at three different types of systems. CMS platforms like DNN, Drupal and Wordpress are generally very flexible and scalable systems that could easily handle my blogging needs. The one area where these tools fall short is that they all have hundreds of features that overkill if you are just looking for a blog. Each of these features steals CPU cycles and creates a potential security risk. This results in needing higher end hosting resources which means I would be spending more time on maintaining the system rather than focusing on the blog. As anyone who has ever had to drop everything to upgrade their site due to a security issue knows, this is not an insignificant issue.&lt;/p&gt;
&lt;p&gt;The second set of systems I looked at are dedicated blogging platforms. In recent years, the number of blogging platforms has been shrinking. The only real option that I see today is Ghost or Medium. While both of these are well established options I didn't feel that I would have the necessary control if I went with Medium and I felt like the maintenance costs for Ghost would still be a bit high.&lt;/p&gt;
&lt;p&gt;The final set of systems I considered were static site generators. Site generators are interesting to me since they ultimately just aid in creating static HTML sites. HTML sites are about as scalable as you can get since all of the content can be cached and there is no server processing needed to serve the content. With some of the hosting options available, I could serve up the site for almost no cost. Most of the site generators I evaluated supported extensible generation pipelines and some sort of markdown or scripting language for controlling the visual aspects of the site.&lt;/p&gt;
&lt;p&gt;The site generation option ticked off every feature on my wish list.&lt;/p&gt;
&lt;h2 id="picking-a-site-generator"&gt;Picking a Site Generator&lt;/h2&gt;
&lt;p&gt;A couple years ago, Phil Haack began &lt;a href="http://www.shopsmith.com/ownersite/catalog/l_univlathetoolrest.htm"&gt;hosting his blog on GitHub&lt;/a&gt;. This really intrigued me. By hosting on GitHub, Phil completely eliminated his maintenance efforts. GitHub serves up millions of pageviews every day so my few page views won't even be noticed. Even a twitter mention by &lt;a href="https://www.hanselman.com/"&gt;Scott Hanselman&lt;/a&gt; won't be enough to swamp my blog with traffic. GitHub definitely looked like a good, albeit unusual, hosting option. And it is totally free which means that the wife acceptance factor is very high.&lt;/p&gt;
&lt;p&gt;There are many great &lt;a href="https://www.staticgen.com/"&gt;static site generators&lt;/a&gt; to choose from. I knew that there would be one that was just right for my purposes.&lt;/p&gt;
&lt;p&gt;The GitHub Pages feature that I would be leveraging to host my blog is nice. It includes full support for Jekyll, a very popular static site generator. Unfortunately, Jekyll is written in Ruby.  While that was not a deal killer, it added a bit of friction to getting started, and would potentially complicate things whenever I wanted to extend the platform. I had previous experience building a site in &lt;a href="http://www.sphinx-doc.org/en/stable/"&gt;Sphinx&lt;/a&gt; and Python, and I learned the hard way that learning a new language and a new tool is a big task that complicates the site building process. I have worked in many different programming languages, but Ruby is not one of them so I wanted to avoid Jekyll for this project if I could.&lt;/p&gt;
&lt;p&gt;After exploring a handful of different static generators, I finally settled on &lt;a href="http://wyam.io"&gt;Wyam&lt;/a&gt; as being the best fit for me. Not only is it written in .Net (C#), the project appears to be &lt;a href="https://github.com/Wyamio/Wyam"&gt;actively maintained&lt;/a&gt; and the author is very responsive to &lt;a href="https://gitter.im/Wyamio/Wyam"&gt;questions on Gitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Wyam is very similar to most generators I evaluated. It includes support for creating my own themes. In Wyam Themes are built using Razor Pages. This allows me to use all of my ASP.Net skills for hand-crafting my own custom theme. Although Wyam includes five different built-in themes out of the box, I much prefer to craft my own theme so that my site reflects my personal tastes.&lt;/p&gt;
&lt;p&gt;On the content side Wyam includes standard support for creating my pages with markdown. This makes it easy to create content without a lot of fuss. When I need a little more control over the final markup, I can always create my pages using Razor script. This gives me the full power of HTML and C# so I can get as fancy as I want for those few pages where the extra control may be necessary.&lt;/p&gt;
&lt;p&gt;All document generation in Wyam is the result of running a set of input files through a number of pre-written pipelines. These pipelines take the input files and generate the HTML, CSS and JavaScript for my final site. In Wyam these pipelines are called recipes. Out of the box there are recipes for Blogs, BookSites and Documentation Sites. With support for markdown, Razor, LESS, SASS, JSON and YAML, I have just about everything I need to create beautiful sites. Of course, if the built-in recipes don't suit my needs, I can easily craft my own or customize the pre-built recipes to suit my particular needs. If desired I could easily extend Wyam to include support for &lt;a href="http://dotliquidmarkup.org/"&gt;Liquid markup&lt;/a&gt;, add support for frontmatter written in XML or any number of interesting customizations. I am in complete control, and I don't have to make any changes to the core Wyam platform to make these enhancements. That is exactly the kind of control that I was looking for.&lt;/p&gt;
&lt;h2 id="just-a-few-comments"&gt;Just a Few Comments&lt;/h2&gt;
&lt;p&gt;The heart of the blogging experience focuses on publishing articles. This is a task that any decent static site generator can handle with ease. But a blog is about more than just publishing articles. It is about engaging in a conversation with your readers. It is about expressing your views, sharing your knowledge and then interacting with your readers to get their viewpoint. Commenting then becomes the soul of your blog. It is where your ideas meet the real world and are challenged or confirmed.&lt;/p&gt;
&lt;p&gt;Ten years ago, commenting systems were fully integrated into blogging platforms. If you didn't like the comment management features of your blog platform, then your only option was to change platforms. Today there are a number of great commenting options for blogs.&lt;/p&gt;
&lt;p&gt;Disqus and Facebook are two of the largest commenting systems out there. They are easy to integrate and they can handle whatever load you throw at them. I like both of these options but whatever reason, they just didn't resonate with me.&lt;/p&gt;
&lt;p&gt;When I looked at Utteranc.es, I was intrigued. Utteranc.es uses the GitHub API to integrate the GitHub issue comment system into your blog. When the first comment is posted to a specific post, Utteranc.es creates a new issue in your predefined GitHub repository, and adds the comment to the issue. Each blog post will have an associated GitHub issue. Since I was planning to use GitHub to host my site source code and to serve up the blog from GitHub pages, it just seemed a natural fit to also use GitHub for hosting the comments for the blog. And as an added bonus, it is completely free.&lt;/p&gt;
&lt;h2 id="performance-and-security"&gt;Performance and Security&lt;/h2&gt;
&lt;p&gt;In today's web environment it is important to consider the performance and security aspects of running your site. Since GitHub is handling all of the hosting duties for my site, I am fairly confident that I won't have any issues with scaling. One of the downsides of using GitHub for hosting my blog is that GitHub does not offer SSL suport for serving GitHub pages with a custom domain. Fortunately, this is easily remedied by using CloudFlare. Not only will this add SSL support, but it also means that all of my content is served from a CDN. Other than comments, the site is purely static content so I can be very aggressive with caching. The comments are loaded using JavaScript so it should be unaffected by the caching. CloudFlare offers a lot of additional features, but for basic CDN and SSL needs CloudFlare offers a free plan for non-commercial use.&lt;/p&gt;
&lt;h2 id="publishing"&gt;Publishing&lt;/h2&gt;
&lt;p&gt;Since Wyam is a static site generator, I will need to run Wyam after every blog post is completed. That complicate the process of publishing my blog. Fortunately for me, there are many continuous integration systems that integrate with GitHub. Many of the most popular CI systems run on Linux and won't work for this project. AppVeyor is a popular CI tool that works great for .Net projects. Wyam has great documentation showing how to &lt;a href="https://wyam.io/docs/deployment/appveyor"&gt;use AppVeyor with Wyam and GitHub&lt;/a&gt;. As you might have guessed, AppVeyor has a free plan that works well for my needs.&lt;/p&gt;
&lt;h2 id="wrapping-it-up"&gt;Wrapping it Up&lt;/h2&gt;
&lt;p&gt;I don't know how many servers are involved in running my site, and honestly I don't really care, and really that is the whole point of serverless computing. I can focus on writing my blog without worrying about any of the hosting concerns. This blogging approach is not for everyone. Wyam, GitHub, Utteranc.es, AppVeyor and CloudFlare are not going to suddenly supplant WordPress as the leading blogging platform. I am just getting started with this new system and I expect that in time I will find new features that I would like to add to my site. I am confident that Wyam is flexible enough to grow with my needs. And the best part of this whole configuration is that I am able to run a secure, high performance blog site for free.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>The Accidental Geek: A New Beginning</title>
			<link>https://joe.brinkman.me/posts/a-new-beginning</link>
			<description>&lt;p&gt;In February 2003, I created a new website under the name "The Accidental Geek". This site was built using a new web application framework called IBuySpy Workshop and was a place where I could blog about my technology passions. I never intended to become a geek, but I fell in love with electronics as a young kid, and later moved into programming as computers became more accessible. The name seemed to fit: and the domain was available.&lt;/p&gt;</description>
			<enclosure url="https://joe.brinkman.me/assets/image/Header.png" length="0" type="image" />
			<guid>https://joe.brinkman.me/posts/a-new-beginning</guid>
			<pubDate>Sat, 14 Oct 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;In February 2003, I created a new website under the name &amp;quot;The Accidental Geek&amp;quot;. This site was built using a new web application framework called IBuySpy Workshop and was a place where I could blog about my technology passions. I never intended to become a geek, but I fell in love with electronics as a young kid, and later moved into programming as computers became more accessible. The name seemed to fit: and the domain was available.&lt;/p&gt;
&lt;p&gt;As many of you know, IbuySpy Workshop became DotNetNuke, which later became &lt;a href="http://www.dnnsoftware.com"&gt;DNN&lt;/a&gt;. When I started using IBuySpy Workshop, I immediately fell in love with the possibilities. Within just a couple months I quit my job and started TAG Software, a development company focused on this new framework.&lt;/p&gt;
&lt;p&gt;For the next two years, I spent all my spare time contibuting code to the DotNetNuke project, some of which is still in DNN today. I was never really able to get TAG Software off the ground as I got sucked back into my previous company to help launch a new J2EE dev framework. Even with the shuttering of TAG Software, DNN was still my passion and I continued to work on it in whatever spare time I had available.&lt;/p&gt;
&lt;p&gt;In 2005 myself and the other leaders of the DNN project decided it was time to focus more resources on DNN so I quit my job once again.  Over the next year Shaun Walker, Scott Willhite, Nik Kalyani and myself worked to shutdown our other businesses and begin focusing all of our efforts on managing and growing the project. In September of 2006 we officially incorporated our new company - DotNetNuke Corp.&lt;/p&gt;
&lt;p&gt;Since those early days, I have been 100% focused on building and promoting DNN and DNN Corp. This project has been my passion for almost 15 years and has been my full-time job for 11. Throughout my time with DNN I have shared my passion for technology and DNN with others through my blog on theaccidentalgeek.com and on DNNSoftware.com, and have taken my passion on the road by speaking at conferences and user groups all over the world.&lt;/p&gt;
&lt;p&gt;During my time with DNN I have worn a lot of hats and been involved in many different aspects of running a software company. I created the DNN Marketplace which was later merged with Snowcovered to become the DNN Store. I led our efforts in creating our OpenForce conferences in the US and Europe, and then managed those conferences for the first three years. I started the QA and Support teams, and worked on the original commercial versions of DNN Professional. I have managed community, been a product manager, started our foray into the cloud and led several R&amp;amp;D projects. Somewhere in all of that I found time to co-author two books on DNN and author a third eBook on jQuery. It has been an extremely challenging and rewarding experience.&lt;/p&gt;
&lt;p&gt;This summer the DNN Corp executive team made the collective decision that now was the right time to seek an acquirer for the company. As much as we all loved the products we were building and the customers we served, we were not able to apply the financial resources to product or community development that we felt was necessary to really remain competitive in the CMS space. The best thing we could do for our employees, our customers and our community was to find a larger company who saw the potential in DNN and who was willing to invest the needed capital.&lt;/p&gt;
&lt;p&gt;In late august DNN Corp was acquired by ESW Corp which started a &lt;a href="http://www.dnnsoftware.com/community-blog/cid/155443/a-new-chapter-for-dnn"&gt;new chapter for DNN&lt;/a&gt;. As part of the acquisition, I am officially leaving DNN. The end of October will be my last official day as a DNN employee. For the first time in over 15 years, DNN will no longer be a central part of my life.&lt;/p&gt;
&lt;p&gt;Now it is time for me to seek out my next great adventure. I plan to take a couple of months off and explore some of my other passions like woodturning and to see what other great technologies I can sink my teeth into. With my upcoming 20th anniversary this November, my wife and I will finally go on the Hawaiian vacation we had originally planned for our 10th anniversary (this little conference called OpenForce kinda changed those plans). I'll still be around the DNN community for a while and plan to attend and speak at DNN Summit this winter. We'll see after that where my journey leads. If it is even half as enjoyable as my time has been with DNN then I will truly consider myself blessed.&lt;/p&gt;
</content:encoded>
		</item>
	</channel>
</rss>